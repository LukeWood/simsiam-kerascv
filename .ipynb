{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# SimSiam Training with TensorFlow Similarity and KerasCV\n",
    "\n",
    "**Author:** [lukewood](https://lukewood.xyz), Ian Stenbit, Owen Vallis<br>\n",
    "**Date created:** 2022/09/21<br>\n",
    "**Last modified:** 2022/09/21<br>\n",
    "**Description:** Train a KerasCV model using unlabelled data with SimSiam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[TensorFlow similarity](https://github.com/tensorflow/similarity) makes it easy to train\n",
    "KerasCV models on unlabelled corpuses of data using contrastive learning algorithms such\n",
    "as SimCLR, SimSiam, and Barlow Twins.  In this guide, we will train a KerasCV model\n",
    "using the SimSiam implementation from TensorFlow Similarity.\n",
    "\n",
    "## Background\n",
    "\n",
    "Self-supervised learning is an approach to pre-training models using unlabeled data. T\n",
    "his approach drastically increases accuracy when you have very few labeled examples but\n",
    "a lot of unlabelled data.\n",
    "The key insight is that you can train a self-supervised model to learn data\n",
    "representations by contrasting multiple augmented views of the same example.\n",
    "These learned representations capture data invariants, e.g., object translation, color\n",
    "jitter, noise, etc. Training a simple linear classifier on top of the frozen\n",
    "representations is easier and requires fewer labels because the pre-trained model\n",
    "already produces meaningful and generally useful features.\n",
    "\n",
    "Overall, self-supervised pre-training learns representations which are more generic and\n",
    "robust than other approaches to augmented training and pre-training.  An overview of\n",
    "the general contrastive learning process is shown below:\n",
    "\n",
    "![Contrastive overview](https://i.imgur.com/mzaEq3C.png)\n",
    "\n",
    "In this tutorial, we will use the [SimSiam](https://arxiv.org/abs/2011.10566) algorithm\n",
    "for contrastive learning.  As of 2022, SimSiam is the state of the art algorithm for\n",
    "contrastive learning; allowing for unprecedented scores on CIFAR-100 and other datasets.\n",
    "\n",
    "To get started, we will sort out some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import resource\n",
    "\n",
    "low, high = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (high, high))\n",
    "\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import tensorflow_addons as tfa\n",
    "import keras_cv\n",
    "from pathlib import Path\n",
    "from tensorflow_similarity.layers import GeneralizedMeanPooling2D, MetricEmbedding\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tabulate import tabulate\n",
    "import tensorflow_similarity as tfsim  # main package\n",
    "import tensorflow as tf\n",
    "from keras_cv import layers as cv_layers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfsim.utils.tf_cap_memory()  # Avoid GPU memory blow up\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "PRE_TRAIN_EPOCHS = 50\n",
    "VAL_STEPS_PER_EPOCH = 20\n",
    "WEIGHT_DECAY = 5e-4\n",
    "INIT_LR = 3e-2 * int(BATCH_SIZE / 256)\n",
    "WARMUP_LR = 0.0\n",
    "WARMUP_STEPS = 0\n",
    "DIM = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "Next, we will load the STL-10 dataset.  STL-10 is a dataset consisting of 100k unlabelled\n",
    "images, 5k labelled training images, and 10k labelled test images.  Due to this distribution,\n",
    "STL-10 is commonly used as a benchmark for contrastive learning models.\n",
    "\n",
    "First lets load our unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_ds = tfds.load(\"stl10\", split=\"unlabelled\")\n",
    "train_ds = train_ds.map(\n",
    "    lambda entry: entry[\"image\"], num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "train_ds = train_ds.map(\n",
    "    lambda image: tf.cast(image, tf.float32), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "train_ds = train_ds.shuffle(buffer_size=8 * BATCH_SIZE, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, we need to prepare some labelled samples.\n",
    "This is done so that TensorFlow similarity can probe the learned embedding to ensure\n",
    "that the model is learning appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(x_raw_train, y_raw_train), ds_info = tfds.load(\n",
    "    \"stl10\", split=\"train\", as_supervised=True, batch_size=-1, with_info=True\n",
    ")\n",
    "x_raw_train, y_raw_train = tf.cast(x_raw_train, tf.float32), tf.cast(\n",
    "    y_raw_train, tf.float32\n",
    ")\n",
    "x_test, y_test = tfds.load(\n",
    "    \"stl10\",\n",
    "    split=\"test\",\n",
    "    as_supervised=True,\n",
    "    batch_size=-1,\n",
    ")\n",
    "x_test, y_test = tf.cast(x_test, tf.float32), tf.cast(y_test, tf.float32)\n",
    "\n",
    "# Compute the indicies for query, index, val, and train splits\n",
    "query_idxs, index_idxs, val_idxs, train_idxs = [], [], [], []\n",
    "for cid in range(ds_info.features[\"label\"].num_classes):\n",
    "    idxs = tf.random.shuffle(tf.where(y_raw_train == cid))\n",
    "    idxs = tf.reshape(idxs, (-1,))\n",
    "    query_idxs.extend(idxs[:100])  # 200 query examples per class\n",
    "    index_idxs.extend(idxs[100:200])  # 200 index examples per class\n",
    "    val_idxs.extend(idxs[200:300])  # 100 validation examples per class\n",
    "    train_idxs.extend(idxs[300:])  # The remaining are used for training\n",
    "\n",
    "random.shuffle(query_idxs)\n",
    "random.shuffle(index_idxs)\n",
    "random.shuffle(val_idxs)\n",
    "random.shuffle(train_idxs)\n",
    "\n",
    "\n",
    "def create_split(idxs: list) -> tuple:\n",
    "    x, y = [], []\n",
    "    for idx in idxs:\n",
    "        x.append(x_raw_train[int(idx)])\n",
    "        y.append(y_raw_train[int(idx)])\n",
    "    return tf.convert_to_tensor(np.array(x), dtype=tf.float32), tf.convert_to_tensor(\n",
    "        np.array(y), dtype=tf.int64\n",
    "    )\n",
    "\n",
    "\n",
    "x_query, y_query = create_split(query_idxs)\n",
    "x_index, y_index = create_split(index_idxs)\n",
    "x_val, y_val = create_split(val_idxs)\n",
    "x_train, y_train = create_split(train_idxs)\n",
    "\n",
    "PRE_TRAIN_STEPS_PER_EPOCH = tf.data.experimental.cardinality(train_ds) // BATCH_SIZE\n",
    "PRE_TRAIN_STEPS_PER_EPOCH = int(PRE_TRAIN_STEPS_PER_EPOCH.numpy())\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            [\"train\", tf.data.experimental.cardinality(train_ds), None],\n",
    "            [\"val\", x_val.shape, y_val.shape],\n",
    "            [\"query\", x_query.shape, y_query.shape],\n",
    "            [\"index\", x_index.shape, y_index.shape],\n",
    "            [\"test\", x_test.shape, y_test.shape],\n",
    "        ],\n",
    "        headers=[\"Examples\", \"Labels\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Augmentations\n",
    "Self-supervised networks require at least two augmented \"views\" of each example. This can be created using a DataSet and an augmentation function. The DataSet treats each example in the batch as its own class and then the augment function produces two separate views for each example.\n",
    "\n",
    "This means the resulting batch will yield tuples containing the two views, i.e.,\n",
    "Tuple[(BATCH_SIZE, 32, 32, 3), (BATCH_SIZE, 32, 32, 3)].\n",
    "\n",
    "TensorFlow Similarity provides several random augmentation functions, and here we combine augmenters from the simCLR module to replicate the augmentations used in simsiam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Augmentation\n",
    "\n",
    "Now that we have all of our datasets produced, we can move on to dataset augmentation.\n",
    "Using KerasCV, it is trivial to construct an augmenter that performs as the one\n",
    "described in the original SimSiam paper.  Lets do that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "target_size = (96, 96)\n",
    "crop_area_factor = (0.08, 1)\n",
    "aspect_ratio_factor = (3 / 4, 4 / 3)\n",
    "grayscale_rate = 0.2\n",
    "color_jitter_rate = 0.8\n",
    "brightness_factor = 0.2\n",
    "contrast_factor = 0.8\n",
    "saturation_factor = (0.3, 0.7)\n",
    "hue_factor = 0.2\n",
    "\n",
    "augmenter = keras_cv.layers.Augmenter(\n",
    "    [\n",
    "        cv_layers.RandomFlip(\"horizontal\"),\n",
    "        cv_layers.RandomCropAndResize(\n",
    "            target_size,\n",
    "            crop_area_factor=crop_area_factor,\n",
    "            aspect_ratio_factor=aspect_ratio_factor,\n",
    "        ),\n",
    "        cv_layers.MaybeApply(\n",
    "            cv_layers.Grayscale(output_channels=3), rate=grayscale_rate\n",
    "        ),\n",
    "        cv_layers.MaybeApply(\n",
    "            cv_layers.RandomColorJitter(\n",
    "                value_range=(0, 255),\n",
    "                brightness_factor=brightness_factor,\n",
    "                contrast_factor=contrast_factor,\n",
    "                saturation_factor=saturation_factor,\n",
    "                hue_factor=hue_factor,\n",
    "            ),\n",
    "            rate=color_jitter_rate,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, lets pass our images through this pipeline.\n",
    "Note that KerasCV supports batched augmentation, so batching before\n",
    "augmentation dramatically improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "@tf.function()\n",
    "def process(img):\n",
    "    return augmenter(img), augmenter(img)\n",
    "\n",
    "\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.shuffle(1024)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(x_val)\n",
    "val_ds = val_ds.repeat()\n",
    "val_ds = val_ds.shuffle(1024)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"train_ds\", train_ds)\n",
    "print(\"val_ds\", val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Lets visualize our pairs using the `tfsim.visualization` utility package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "display_imgs = next(train_ds.as_numpy_iterator())\n",
    "max_pixel = np.max([display_imgs[0].max(), display_imgs[1].max()])\n",
    "min_pixel = np.min([display_imgs[0].min(), display_imgs[1].min()])\n",
    "\n",
    "tfsim.visualization.visualize_views(\n",
    "    views=display_imgs,\n",
    "    num_imgs=16,\n",
    "    views_per_col=8,\n",
    "    max_pixel_value=max_pixel,\n",
    "    min_pixel_value=min_pixel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Model Creation\n",
    "\n",
    "Now that our data and augmentation pipeline is setup, we can move on to\n",
    "constructing the contrastive learning pipeline.  First, lets produce a backbone.\n",
    "For this task, we will use a KerasCV ResNet18 model as the backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_backbone(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    x = keras_cv.models.ResNet18(\n",
    "        input_shape=input_shape,\n",
    "        include_rescaling=True,\n",
    "        include_top=False,\n",
    "    )(x)\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    return tfsim.models.SimilarityModel(inputs, x)\n",
    "\n",
    "\n",
    "backbone = get_backbone((96, 96, 3))\n",
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This MLP is common to all the self-supervised models and is typically a stack of 3\n",
    "layers of the same size. However, SimSiam only uses 2 layers for the smaller CIFAR\n",
    "images. Having too much capacity in the models can make it difficult for the loss to\n",
    "stabilize and converge.\n",
    "\n",
    "Additionally, the SimSiam paper found that disabling the center and scale parameters\n",
    "can lead to a small boost in the final loss.\n",
    "\n",
    "NOTE This is the model output that is returned by `ContrastiveModel.predict()` and\n",
    "represents the distance based embedding. This embedding can be used for the KNN\n",
    "lookups and matching classification metrics. However, when using the pre-train\n",
    "model for downstream tasks, only the `ContrastiveModel.backbone` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_projector(input_dim, dim, activation=\"relu\", num_layers: int = 3):\n",
    "    inputs = tf.keras.layers.Input((input_dim,), name=\"projector_input\")\n",
    "    x = inputs\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        x = tf.keras.layers.Dense(\n",
    "            dim,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "            name=f\"projector_layer_{i}\",\n",
    "        )(x)\n",
    "        x = tf.keras.layers.BatchNormalization(\n",
    "            epsilon=1.001e-5, name=f\"batch_normalization_{i}\"\n",
    "        )(x)\n",
    "        x = tf.keras.layers.Activation(activation, name=f\"{activation}_activation_{i}\")(\n",
    "            x\n",
    "        )\n",
    "    x = tf.keras.layers.Dense(\n",
    "        dim,\n",
    "        use_bias=False,\n",
    "        kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "        name=\"projector_output\",\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization(\n",
    "        epsilon=1.001e-5,\n",
    "        center=False,  # Page:5, Paragraph:2 of SimSiam paper\n",
    "        scale=False,  # Page:5, Paragraph:2 of SimSiam paper\n",
    "        name=f\"batch_normalization_ouput\",\n",
    "    )(x)\n",
    "    # Metric Logging layer. Monitors the std of the layer activations.\n",
    "    # Degnerate solutions colapse to 0 while valid solutions will move\n",
    "    # towards something like 0.0220. The actual number will depend on the layer size.\n",
    "    o = tfsim.layers.ActivationStdLoggingLayer(name=\"proj_std\")(x)\n",
    "    projector = tf.keras.Model(inputs, o, name=\"projector\")\n",
    "    return projector\n",
    "\n",
    "\n",
    "projector = get_projector(input_dim=backbone.output.shape[-1], dim=DIM, num_layers=2)\n",
    "projector.summary()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally, we must construct the predictor.  The predictor is used in SimSiam, and is a\n",
    "simple stack of two MLP layers, containing a bottleneck in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_predictor(input_dim, hidden_dim=512, activation=\"relu\"):\n",
    "    inputs = tf.keras.layers.Input(shape=(input_dim,), name=\"predictor_input\")\n",
    "    x = inputs\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        hidden_dim,\n",
    "        use_bias=False,\n",
    "        kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "        name=\"predictor_layer_0\",\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization(\n",
    "        epsilon=1.001e-5, name=\"batch_normalization_0\"\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Activation(activation, name=f\"{activation}_activation_0\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        input_dim,\n",
    "        kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "        name=\"predictor_output\",\n",
    "    )(x)\n",
    "    # Metric Logging layer. Monitors the std of the layer activations.\n",
    "    # Degnerate solutions colapse to 0 while valid solutions will move\n",
    "    # towards something like 0.0220. The actual number will depend on the layer size.\n",
    "    o = tfsim.layers.ActivationStdLoggingLayer(name=\"pred_std\")(x)\n",
    "    predictor = tf.keras.Model(inputs, o, name=\"predictor\")\n",
    "    return predictor\n",
    "\n",
    "\n",
    "predictor = get_predictor(input_dim=DIM, hidden_dim=512)\n",
    "predictor.summary()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Training\n",
    "\n",
    "First, we need to initialize our training model, loss, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss = tfsim.losses.SimSiamLoss(projection_type=\"cosine_distance\", name=\"simsiam\")\n",
    "\n",
    "contrastive_model = tfsim.models.ContrastiveModel(\n",
    "    backbone=backbone,\n",
    "    projector=projector,\n",
    "    predictor=predictor,  # NOTE: simiam requires predictor model.\n",
    "    algorithm=\"simsiam\",\n",
    "    name=\"simsiam\",\n",
    ")\n",
    "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=INIT_LR,\n",
    "    decay_steps=PRE_TRAIN_EPOCHS * PRE_TRAIN_STEPS_PER_EPOCH,\n",
    ")\n",
    "wd_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=WEIGHT_DECAY,\n",
    "    decay_steps=PRE_TRAIN_EPOCHS * PRE_TRAIN_STEPS_PER_EPOCH,\n",
    ")\n",
    "optimizer = tfa.optimizers.SGDW(\n",
    "    learning_rate=lr_decayed_fn, weight_decay=wd_decayed_fn, momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next we can compile the model the same way you compile any other Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "contrastive_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We track the training using several callbacks.\n",
    "\n",
    "* **EvalCallback** creates an index at the end of each epoch and provides a proxy for the nearest neighbor matching classification using `binary_accuracy`.\n",
    "* **TensordBoard** and **ModelCheckpoint** are provided for tracking the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"./\")\n",
    "log_dir = DATA_PATH / \"models\" / \"logs\" / f\"{loss.name}_{time.time()}\"\n",
    "chkpt_dir = DATA_PATH / \"models\" / \"checkpoints\" / f\"{loss.name}_{time.time()}\"\n",
    "\n",
    "callbacks = [\n",
    "    tfsim.callbacks.EvalCallback(\n",
    "        tf.cast(x_query, tf.float32),\n",
    "        y_query,\n",
    "        tf.cast(x_index, tf.float32),\n",
    "        y_index,\n",
    "        metrics=[\"binary_accuracy\"],\n",
    "        k=1,\n",
    "        tb_logdir=log_dir,\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        update_freq=100,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=chkpt_dir,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "All that is left to do is run fit()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "print(train_ds)\n",
    "print(val_ds)\n",
    "history = contrastive_model.fit(\n",
    "    train_ds,\n",
    "    epochs=PRE_TRAIN_EPOCHS,\n",
    "    steps_per_epoch=PRE_TRAIN_STEPS_PER_EPOCH,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Plotting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.grid()\n",
    "plt.title(f\"{loss.name} - loss\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history[\"proj_std\"], label=\"proj\")\n",
    "if \"pred_std\" in history.history:\n",
    "    plt.plot(history.history[\"pred_std\"], label=\"pred\")\n",
    "plt.grid()\n",
    "plt.title(f\"{loss.name} - std metrics\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history[\"binary_accuracy\"], label=\"acc\")\n",
    "plt.grid()\n",
    "plt.title(f\"{loss.name} - match metrics\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Fine Tuning on the Labelled Data\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "eval_augmenter = keras_cv.layers.Augmenter(\n",
    "    [\n",
    "        keras_cv.layers.RandomCropAndResize(\n",
    "            (96, 96), crop_area_factor=(0.2, 1.0), aspect_ratio_factor=(1.0, 1.0)\n",
    "        ),\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_raw_train, tf.keras.utils.to_categorical(y_raw_train, 10))\n",
    ")\n",
    "eval_train_ds = eval_train_ds.repeat()\n",
    "eval_train_ds = eval_train_ds.shuffle(1024)\n",
    "eval_train_ds = eval_train_ds.map(lambda x, y: (eval_augmenter(x), y), tf.data.AUTOTUNE)\n",
    "eval_train_ds = eval_train_ds.batch(BATCH_SIZE)\n",
    "eval_train_ds = eval_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, tf.keras.utils.to_categorical(y_test, 10))\n",
    ")\n",
    "eval_val_ds = eval_val_ds.repeat()\n",
    "eval_val_ds = eval_val_ds.shuffle(1024)\n",
    "eval_val_ds = eval_val_ds.batch(BATCH_SIZE)\n",
    "eval_val_ds = eval_val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Benchmark Against a Naive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "TEST_EPOCHS = 50\n",
    "TEST_STEPS_PER_EPOCH = x_raw_train.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "def get_eval_model(img_size, backbone, total_steps, trainable=True, lr=1.8):\n",
    "    backbone.trainable = trainable\n",
    "    inputs = tf.keras.layers.Input((img_size, img_size, 3), name=\"eval_input\")\n",
    "    x = backbone(inputs, training=trainable)\n",
    "    o = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs, o)\n",
    "    cosine_decayed_lr = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=lr, decay_steps=total_steps\n",
    "    )\n",
    "    opt = tf.keras.optimizers.SGD(cosine_decayed_lr, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "no_pt_eval_model = get_eval_model(\n",
    "    img_size=96,\n",
    "    backbone=get_backbone((96, 96, 3)),\n",
    "    total_steps=TEST_EPOCHS * TEST_STEPS_PER_EPOCH,\n",
    "    trainable=True,\n",
    "    lr=1e-3,\n",
    ")\n",
    "no_pt_history = no_pt_eval_model.fit(\n",
    "    eval_train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=TEST_EPOCHS,\n",
    "    steps_per_epoch=TEST_STEPS_PER_EPOCH,\n",
    "    validation_data=eval_val_ds,\n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Pretty bad results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "pt_eval_model = get_eval_model(\n",
    "    img_size=96,\n",
    "    backbone=contrastive_model.backbone,\n",
    "    total_steps=TEST_EPOCHS * TEST_STEPS_PER_EPOCH,\n",
    "    trainable=False,\n",
    "    lr=30.0,\n",
    ")\n",
    "pt_eval_model.summary()\n",
    "pt_history = pt_eval_model.fit(\n",
    "    eval_train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=TEST_EPOCHS,\n",
    "    steps_per_epoch=TEST_STEPS_PER_EPOCH,\n",
    "    validation_data=eval_val_ds,\n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Far superior results!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "simsiam-with-kerascv",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}